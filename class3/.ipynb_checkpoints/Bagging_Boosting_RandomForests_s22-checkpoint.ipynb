{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "phantom-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "falling-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numeric-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ee950",
   "metadata": {},
   "source": [
    "Let's review last time and run through a few of the methods we've discussed so far:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-rebate",
   "metadata": {},
   "source": [
    "We built decision trees for regression last time. That meant we partition feature space by repeatedly choosing a cut point for the variable that gives the maximal reduction in RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-attempt",
   "metadata": {},
   "source": [
    "<img src=\"TreePic.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-investigator",
   "metadata": {},
   "source": [
    "Terminal nodes in the tree become increasingly pure (all values in a node are close to the average)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-hopkins",
   "metadata": {},
   "source": [
    "Growing deep trees lead to low bias (might have enough nodes so that training error is 0) but high variance and poor generalizablity to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-advocate",
   "metadata": {},
   "source": [
    "In order to reduce variance and improve performance on new data we introduced the idea of cost complexity pruning..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-facing",
   "metadata": {},
   "source": [
    "Grow a deep tree and prune it back by removing nodes that provide the least benefit in RSS. Did this by minimizing RSS plus a penalty on the tree depth (complexity). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-extra",
   "metadata": {},
   "source": [
    "This is very much like Ridge regression. Optimize the penalty parameter $\\alpha$ using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-diversity",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-indicator",
   "metadata": {},
   "source": [
    "We were using NBA player salary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cardiac-calendar",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'players.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-31e14f2f8d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'players.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'salaries_1985to2018.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'players.csv'"
     ]
    }
   ],
   "source": [
    "pl=pd.read_csv('players.csv')\n",
    "sal=pd.read_csv('salaries_1985to2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_sal=sal[['player_id','salary','season_end']].groupby('player_id',as_index=False).mean()\n",
    "players=pl.merge(gp_sal,how='left',left_on='_id',right_on='player_id')\n",
    "players=players[players['salary'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "players.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "players['logsalary']=np.log(players['salary'])\n",
    "players['logG'] =np.log(players['career_G'])\n",
    "pdf=players[['career_AST', 'career_FG%','career_FG3%', 'career_FT%', 'career_G', 'career_PER', 'career_PTS','career_TRB', 'career_WS', 'career_eFG%',\n",
    "       'logsalary', 'logG','season_end']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['career_FG%']=pd.to_numeric(pdf['career_FG%'],errors='coerce')\n",
    "pdf['career_FG3%']=pd.to_numeric(pdf['career_FG3%'],errors='coerce')\n",
    "pdf['career_FT%']=pd.to_numeric(pdf['career_FT%'],errors='coerce')\n",
    "pdf['career_PER']=pd.to_numeric(pdf['career_PER'],errors='coerce')\n",
    "pdf['career_TRB']=pd.to_numeric(pdf['career_TRB'],errors='coerce')\n",
    "pdf['career_WS']=pd.to_numeric(pdf['career_WS'],errors='coerce')\n",
    "pdf['career_eFG%']=pd.to_numeric(pdf['career_eFG%'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=pdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pdf.drop('logsalary',axis=1)\n",
    "y=pdf['logsalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tree = DecisionTreeRegressor(random_state=2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(full_tree.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tree.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(mean_squared_error(full_tree.predict(X_test), y_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "nfeat=X.shape[1]\n",
    "plt.barh(np.arange(nfeat),full_tree.feature_importances_,align='center')\n",
    "plt.yticks(np.arange(nfeat),list(X.columns))\n",
    "plt.ylim(-1,nfeat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf90467",
   "metadata": {},
   "source": [
    "Last time we didn't include season_end... but it's an important feature and adds considerably to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095eb30",
   "metadata": {},
   "source": [
    "Now, we know tyhat the full tree overfits, so we use cost complexity pruning to improve prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = full_tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(ccp_alphas, impurities, marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total MSE of leaves\")\n",
    "ax.set_title(\"Total MSE vs effective alpha for training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e44c90",
   "metadata": {},
   "source": [
    "See that as we prune back the tree (make it shorter), the bias increases: nodes become less pure, and MSE increases. The hope is that this decreases overfitting and variance and leads to better generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ccp_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    reg = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    reg.fit(X_train, y_train)\n",
    "    regs.append(reg)\n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      regs[-1].tree_.node_count, ccp_alphas[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a7e16",
   "metadata": {},
   "source": [
    "The last tree with the largest value of alpha penalizes deep trees so much that we have depth 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = regs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_counts = [reg.tree_.node_count for reg in regs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_counts = [reg.tree_.node_count for reg in regs]\n",
    "depth = [reg.tree_.max_depth for reg in regs]\n",
    "fig, ax = plt.subplots(2, 1,figsize=(8,6))\n",
    "ax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker='o', drawstyle=\"steps-post\",color='g')\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [reg.score(X_train, y_train) for reg in regs]\n",
    "test_scores = [reg.score(X_test, y_test) for reg in regs]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"R^2\")\n",
    "ax.set_title(\"R^2 vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [mean_squared_error(reg.predict(X_train), y_train) for reg in regs]\n",
    "test_scores = [mean_squared_error(reg.predict(X_test),y_test) for reg in regs]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"MSE vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3908f",
   "metadata": {},
   "source": [
    "These are useful pictures to understand what is happening, but we're cheating by using the test set to get a sense of where the optimal alpha lives (note: between 0 and 0.05). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745e2e6",
   "metadata": {},
   "source": [
    "The right way to find the optimal alpha is cross validation. This is computationally expensive: for each possible value of alpha we build the decision tree regressor on 4 training folds and validate on the hold-out test fold. We repeat 5 times using each fold as the test fold once. Keep track of the average CV error. But number of models we're building here is the length of the list of alphas (1400) times 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-marshall",
   "metadata": {},
   "source": [
    "** WARNING ** the cell below is slow to run on the full list of alphas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres=[]\n",
    "for a in ccp_alphas:\n",
    "    reg = DecisionTreeRegressor(random_state=0, ccp_alpha= a)\n",
    "    cvreg = cross_validate(reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cvres.append(cvreg['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas[1392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "optalp=ccp_alphas[np.argmax(cvres)]\n",
    "optalp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3b237",
   "metadata": {},
   "source": [
    "Note: this alpha--obtained via cross validation--agrees with what we expected from the pictires above on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204553c7",
   "metadata": {},
   "source": [
    "Now re-fit with ```optalp``` on the full training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "regO = DecisionTreeRegressor(random_state=0, ccp_alpha=optalp).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103783b",
   "metadata": {},
   "source": [
    "How deep is this tree? How does it compare to the full tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regO.get_depth(),':',full_tree.get_depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f502a0",
   "metadata": {},
   "source": [
    "Compare\n",
    "metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The pruned tree has R-squared score {} while the full tree has R-squared {}\".format(regO.score(X_test,y_test),full_tree.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The pruned tree has mean-squared-error score {} while the full tree has mean-squared-error {}\".format(mean_squared_error(regO.predict(X_test),y_test),mean_squared_error(full_tree.predict(X_test),y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db8954",
   "metadata": {},
   "source": [
    "The pruned tree is significantly better on both metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(y_test,regO.predict(X_test))\n",
    "plt.xlabel(\"acutal log-salary\")\n",
    "plt.ylabel(\"predicted log-salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-circle",
   "metadata": {},
   "source": [
    "We've been working with trees, but is it worth it? Are we doing better than plain old linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols=LinearRegression().fit(X_train,y_train)\n",
    "mean_squared_error(ols.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-newsletter",
   "metadata": {},
   "source": [
    "Alas, still not better than OLS regression! Maybe Ridge regression is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(5,-3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgemod = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "ridgemod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=ridgemod.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgemod.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-boards",
   "metadata": {},
   "source": [
    "Virtually no improvement using Ridge Regression here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c32d02",
   "metadata": {},
   "source": [
    "Maybe ***knn*** regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b845a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv_results=[]\n",
    "for k in range(1,50):\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "    cv_nn = cross_validate(knn_regressor, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    knn_cv_results.append(cv_nn['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bec7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(knn_cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg_model=KNeighborsRegressor(n_neighbors=7).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ca8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c698ec9",
   "metadata": {},
   "source": [
    "Worse! Let's see if we can improve our tree regressor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06915cbf",
   "metadata": {},
   "source": [
    "WARNING: Comparing different models' performances on the test set in order to choose the best one is *also* cheating. We really need a trianing set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d8383",
   "metadata": {},
   "source": [
    "First idea:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-surname",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-arctic",
   "metadata": {},
   "source": [
    "Idea: Create many decision trees (grown deep: no pruning). We know they will overfit-- i.e, will have high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-moderator",
   "metadata": {},
   "source": [
    "Reduce variance by *averaging*. People's heights will have much more variation then average heights of groups of 10 people. If we had many trees, and averaged their results, we might get a lower bias model with reduced variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3808a97",
   "metadata": {},
   "source": [
    "Indeed, if a random variable $X$ has variance $\\sigma^2$ then the distribution of the sample mean $\\overline{X}$ has variance $\\frac{\\sigma^2}{\\sqrt{n}}$ where $n$ is sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1beb4",
   "metadata": {},
   "source": [
    "Problem: there's only one training set-- so how do we fit different trees to average? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb6615",
   "metadata": {},
   "source": [
    "The bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554559e5",
   "metadata": {},
   "source": [
    "### A short digression on bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a11fa",
   "metadata": {},
   "source": [
    "Back to Boston marathon, 2017. Let's look at the distribution of runners' paces (in minutes per mile):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5072e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar=pd.read_csv('marathon_results_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_minutes(row):\n",
    "    x= row['Official Time'].split(\":\")\n",
    "    return (int(x[0])*3600+int(x[1])*60+int(x[2]))/(60*26.2)\n",
    "mar['Pace']=mar.apply(to_minutes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c87a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar['Pace'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7dd398",
   "metadata": {},
   "source": [
    "We actually know the true populaiton mean/median paces: This is ***everyone***, not a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d83fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean time: {}\".format(np.round(mar['Pace'].mean(),3)), \"Median Time: {}\".format(np.round(mar['Pace'].median(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4720d",
   "metadata": {},
   "source": [
    "But what if we did only have a sample? Say of 100 results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d540993",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp=mar.sample(n=100,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e347dbc",
   "metadata": {},
   "source": [
    "Sample mean and median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3089de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(samp['Pace'].mean(),3),\":\",np.round(samp['Pace'].median(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19a29a",
   "metadata": {},
   "source": [
    "A typical problem in statistics is to use the sample data to give a 95% confidence interval for the mean: an interval which captures the true (fixed) population mean witrh probability 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp['Pace'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001fd0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30055268",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_crit = np.abs(stats.t.ppf((1-.95)/2,99)) \n",
    "t_crit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03661b",
   "metadata": {},
   "source": [
    "Slightly bigger than the ```z_crit``` of 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a4aae",
   "metadata": {},
   "source": [
    "$$\n",
    "\\overline{x} \\pm t_{.95,df}\\cdot\\frac{s}{\\sqrt{n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f60224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(\",samp['Pace'].mean()-t_crit*samp['Pace'].std()/np.sqrt(100),\",\",\n",
    "samp['Pace'].mean()+t_crit*samp['Pace'].std()/np.sqrt(100),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a35bf8",
   "metadata": {},
   "source": [
    "^^ Does catch the true mean pace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7176325",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar['Pace'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35284a8a",
   "metadata": {},
   "source": [
    "Note: this relies an assumption of normality of underlying population (which looks false here) or an invocation of the CLT since sample size is large, and interpreting our confidence intervals as *approximate*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd44f0",
   "metadata": {},
   "source": [
    "What if we wanted a confidence interval for the median? Doesn't have such a familiar normal theory that gives CIs. Or what if our population distribution is highly non-normal and sample size is small?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda3f72",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1d392",
   "metadata": {},
   "source": [
    "Treat the sample like the populaiton and sample, repeatedly, with replacement,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81245d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bstrap_mean=[]\n",
    "bstrap_median=[]\n",
    "xbar=samp['Pace'].mean()\n",
    "mbar=samp['Pace'].median()\n",
    "for i in range(10000):\n",
    "    newdf=samp.sample(frac=1,replace=True)\n",
    "    xstar=newdf['Pace'].mean()\n",
    "    mstar=newdf['Pace'].median()\n",
    "    bstrap_mean.append(xstar)\n",
    "    bstrap_median.append(mstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d95563",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))  # make one subplot (ax) on the figure\n",
    "ax.hist(bstrap_mean,bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ceac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))  # make one subplot (ax) on the figure\n",
    "ax.hist(bstrap_median,bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401470d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bstrap_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bstrap_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152cc089",
   "metadata": {},
   "source": [
    "Take the 2.5 and 97.5 percentiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(bstrap_mean,0.025),np.quantile(bstrap_mean,0.975)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa602161",
   "metadata": {},
   "source": [
    "compare with theoretical CI: ( 8.622 , 9.314 ), and true mean of 9.086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(bstrap_median,0.025),np.quantile(bstrap_median,0.975)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dfc37a",
   "metadata": {},
   "source": [
    "^^ Also catches the true median of 8.842 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar['Pace'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f815ed",
   "metadata": {},
   "source": [
    "Bootstrap principle: The sample is to the data as the bootstrap sample is to the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp2=mar.sample(n=100,random_state=5)\n",
    "bstrap_mean2=[]\n",
    "bstrap_median2=[]\n",
    "xbar2=samp2['Pace'].mean()\n",
    "mbar2=samp2['Pace'].median()\n",
    "for i in range(10000):\n",
    "    newdf2=samp2.sample(frac=1,replace=True)\n",
    "    xstar2=newdf2['Pace'].mean()\n",
    "    mstar2=newdf2['Pace'].median()\n",
    "    bstrap_mean2.append(xstar2)\n",
    "    bstrap_median2.append(mstar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7078055",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"samples:\",np.round(xbar2,3),np.round(mbar2,3))\n",
    "print(\"bootstraps:\",np.round(xstar2,3),np.round(mstar2,3))\n",
    "print(\"population:\",np.round(mar['Pace'].mean(),3),np.round(mar['Pace'].median(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79da6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(bstrap_mean2,0.025),np.quantile(bstrap_mean2,0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(bstrap_median2,0.025),np.quantile(bstrap_median2,0.975)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3959f1",
   "metadata": {},
   "source": [
    "Note we missed both here! Got a \"bad\" sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fe6e5",
   "metadata": {},
   "source": [
    "Back to building trees: We wanted to average lots of trees to prevent variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3d58f",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-owner",
   "metadata": {},
   "source": [
    "Sample the training observations (same number) with replacement and fit a decision tree on the resampled data. Each tree only looks at some of the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-gibraltar",
   "metadata": {},
   "source": [
    "If the bootstrapped samples are labeled:\n",
    "$$\n",
    "1,2,3,\\ldots, B,\n",
    "$$\n",
    "and the corresponding (deep) trees are \n",
    "$$\n",
    "f^*_1,f^*_2,\\ldots,f^*_B,\n",
    "$$\n",
    "then for a test observation $x$ we predict:\n",
    "$$\n",
    "f^{\\text{avg}}(x)=\\frac{1}{B}\\sum_{i=1}^Bf^*_i(x)\n",
    "$$\n",
    "and where the * reminds us that each tree is fit on a bootstrap sample of the original training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = BaggingRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=100,oob_score=True,random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2 is {}\".format(regr.score(X_test,y_test)),\":\",\":\", \"MSE is {}\".format(mean_squared_error(regr.predict(X_test),y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-mumbai",
   "metadata": {},
   "source": [
    "Improvement! OLS $R^2$ was 0.745."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-wrist",
   "metadata": {},
   "source": [
    "Added Bonus: The bootstrap gives us a way to estimate test-set error without the actual test set. Since the bootstrap samples the training data for each tree, some observations won't be used in the building of the $i$-th tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-jimmy",
   "metadata": {},
   "source": [
    "These observations are called *out-of-bag* observations (OOB) and we can use them as de facto test observations for that tree. In practice, for an observation $x$ we can average the prediction over all trees that leave $x$ OOB. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-utilization",
   "metadata": {},
   "source": [
    "***Warning: We still need to use a test set.*** But, this could be useful, say, to determine the optimal number of trees to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees=np.linspace(50,500,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890281e",
   "metadata": {},
   "source": [
    "More trees is generally better (but more expensive) so it's usually a question of diminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_res=[]\n",
    "for trs in num_trees:\n",
    "    res = BaggingRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=int(trs),oob_score=True,random_state=0).fit(X_train, y_train)\n",
    "    oob_res.append(res.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_trees,oob_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-banking",
   "metadata": {},
   "source": [
    "Looks like we peak around 400 trees (though only very slightly better than 100 trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees[np.argmax(oob_res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_trs=int(num_trees[np.argmax(oob_res)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = BaggingRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=opt_trs,random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(regr.score(X_test,y_test),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-fisher",
   "metadata": {},
   "source": [
    "Test $R^2$ only slightly lower than the OOB score above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-antarctica",
   "metadata": {},
   "source": [
    "## Random Forests:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-sperm",
   "metadata": {},
   "source": [
    "Another approach to aggregating trees built on bootstrap samples of the data (like bagging), but with a small tweak. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-digest",
   "metadata": {},
   "source": [
    "Each time we make a split in a tree, we do so using a random sample of the available features. If we have $p$ features, we usually choose $\\approx \\sqrt{p}$ features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-secret",
   "metadata": {},
   "source": [
    "Why? Decorrelate the trees and allow weaker signals through. The same features won't dominate ***all*** the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-hungary",
   "metadata": {},
   "source": [
    "Not guaranteed to improve over bagging but can be a big help if we have many correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=400,max_features='sqrt',random_state=0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-dayton",
   "metadata": {},
   "source": [
    "Very similar to straight bagging here (more examples below). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eab0df",
   "metadata": {},
   "source": [
    "We might want to look at feature importances though bagging (and RFs) are not easily interpreted (like a single tree is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "nfeat=X.shape[1]\n",
    "plt.barh(np.arange(nfeat),rf.feature_importances_,align='center')\n",
    "plt.yticks(np.arange(nfeat),list(X.columns))\n",
    "plt.ylim(-1,nfeat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333f746",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd5e53",
   "metadata": {},
   "source": [
    "We have decision tree classifier too, so we can easily build a random forest classifier as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e818fa42",
   "metadata": {},
   "source": [
    "Last time we tried *knn* classifier on the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7303cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcd = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(bcd['data'], columns=bcd['feature_names'])\n",
    "df['target'] = bcd['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a928c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('target',axis=1)\n",
    "y=df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('target',axis=1)\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b0aab",
   "metadata": {},
   "source": [
    "For *knn*, recall that cross validation gave optimal $k=5$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = KNeighborsClassifier(n_neighbors=5)\n",
    "nb5=mod.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbda295",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(nb5.predict(X_test_scaled),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93783ff",
   "metadata": {},
   "source": [
    "Let's compare with a RF classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afe2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f35794",
   "metadata": {},
   "source": [
    "Because of how the decision tree algorithm works we don't need scaling, and can use a mix of categorical and quantitative variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8efcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100,max_features='sqrt',random_state=0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(rfc.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d53d83b",
   "metadata": {},
   "source": [
    "Wow, we did better right off the shelf. We didn't even tune the number of trees so maybe could do even a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "nfeat=X.shape[1]\n",
    "plt.barh(np.arange(nfeat),rfc.feature_importances_,align='center')\n",
    "plt.yticks(np.arange(nfeat),list(X.columns))\n",
    "plt.ylim(-1,nfeat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0fd0b",
   "metadata": {},
   "source": [
    "Nice advantages of a Random Forest:\n",
    "1. Easy to use \"off the shelf\".\n",
    "2. Can handle quantitative predictors, categorical predictors, or a mix.\n",
    "3. Does not require much in the way of parameter tuning.\n",
    "4. Decouples the trees to handle feature colinearity and allow weaker signals through (by chosing a subset of features at each split ).\n",
    "5. Generally performs very well (and very similar to bagging if the features are not particularly correlated).\n",
    "6. Prevents overfitting through averaging (of deep trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64b3ee",
   "metadata": {},
   "source": [
    "BUT... we lose interpretability/simplicity of a single tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-currency",
   "metadata": {},
   "source": [
    "#### Next: Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-penetration",
   "metadata": {},
   "source": [
    "Again -- use multiple trees to attack the problem. BUT, trees are grown sequentially and are kept small (to prevent overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-underground",
   "metadata": {},
   "source": [
    "Start with a single tree $\\hat{f_1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-bargain",
   "metadata": {},
   "source": [
    "Then, build a new tree to improve on the prediction of $\\hat{f_1}$ by fitting the residuals\n",
    "$$\n",
    "y_i-\\hat{f_1}(x_i).\n",
    "$$\n",
    "We get a new model $\\hat{f_2}$ which we add to the old model:\n",
    "$$\n",
    "\\hat{f_1}+\\lambda \\hat{f_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-imaging",
   "metadata": {},
   "source": [
    "$\\lambda$ is a parameter called the learning rate. It's a small-ish number (0.1, 0.01, 0.001) that slows down the learning process allowing more trees to attack the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-milwaukee",
   "metadata": {},
   "source": [
    "Each small tree is a *weak learner* but they combine into a strong learner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-liverpool",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{f}(x) = \\sum_{i=1}^B\\lambda \\hat{f_i}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87e1b4",
   "metadata": {},
   "source": [
    "Let's go back to the NBA salary data (our regression example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a115a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pdf.drop('logsalary',axis=1)\n",
    "y=pdf['logsalary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "breg = GradientBoostingRegressor(random_state=0,learning_rate=0.1,n_estimators=500,max_depth=2).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "breg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-gathering",
   "metadata": {},
   "source": [
    "Tiny improvent over bagging and random forests in this case..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-newman",
   "metadata": {},
   "source": [
    "One challenge in building a boosting model is that we have several parameters to choose. \n",
    "1. The number of trees.\n",
    "2. The max depth of each tree.\n",
    "3. The learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-printing",
   "metadata": {},
   "source": [
    "```sklearn``` has a function to help cross validate over a grid of parameter values. WARNING: It can be slow!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'learning_rate':[0.1,0.01], 'n_estimators':[300,400,500],'max_depth':[2,3,4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmod = GradientBoostingRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a52b8",
   "metadata": {},
   "source": [
    "Might want to stretch legs after running the next cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_regr = GridSearchCV(bmod, parameters)\n",
    "boost_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-chemistry",
   "metadata": {},
   "source": [
    "Lot's of info in here-- we can pull it all into a data frame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(boost_regr.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-nomination",
   "metadata": {},
   "source": [
    "... and pull out the parameter values corresponding to the best CV score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['mean_test_score']==df['mean_test_score'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_breg = GradientBoostingRegressor(random_state=0,learning_rate=0.01,n_estimators=400,max_depth=4).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(best_breg.score(X_test,y_test),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-finland",
   "metadata": {},
   "source": [
    "Very slightly better still. Bagging, RF, boosting are all very similar and outperform Linear Regression / Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-supplement",
   "metadata": {},
   "source": [
    "All of our tree based methods can be used for classification too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-minutes",
   "metadata": {},
   "source": [
    "#### Recall Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-present",
   "metadata": {},
   "source": [
    "Essentially, we need a definition of error in a rectangular region to replace RSS. We will assign all points in $R_m$ to the most common class in $R_m$. So, it would seem natural to use the fraction of observations *not* in that most common class (classes $1,2,\\ldots, n$) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-narrative",
   "metadata": {},
   "source": [
    "$$\n",
    "1-\\max_{k}(\\hat{p}_{mk})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-slide",
   "metadata": {},
   "source": [
    "This turns out to be not quite sensitive enough to decide cuts. Rather we use the Gini-index:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-kentucky",
   "metadata": {},
   "source": [
    "$$\n",
    "G=\\sum_{k} \\hat{p}_{mk}(1-\\hat{p}_{mk})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-dakota",
   "metadata": {},
   "source": [
    "G is small when all class probabilities are near $0$ or $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-announcement",
   "metadata": {},
   "source": [
    "Plot the two values when there are 2 classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals=np.linspace(0,1,100)\n",
    "yvals1=xvals*(1-xvals)+(1-xvals)*(xvals)\n",
    "yvals2= 1-np.maximum(xvals,1-xvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(xvals,yvals1)\n",
    "plt.plot(xvals,yvals2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-blank",
   "metadata": {},
   "source": [
    "G grows more rapidly as $p$ deviates form 0 or 1: more sensitive to impurity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=pd.read_csv('diabetes.csv')\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd=db.drop('Outcome',axis=1)\n",
    "yd=db['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd_train, Xd_test, yd_train, yd_test = train_test_split(Xd,yd,test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=400,random_state=0).fit(Xd_train, yd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(clf.predict(Xd_test),yd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(n_estimators=400, max_features='sqrt',random_state=0).fit(Xd_train,yd_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-fishing",
   "metadata": {},
   "source": [
    "Can do slightly better with max_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(rfclf.predict(Xd_test),yd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_clf = GradientBoostingClassifier(n_estimators=600, learning_rate=0.01,max_depth=1, random_state=0).fit(Xd_train, yd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(bst_clf.predict(Xd_test),yd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "path = single_tree_clf.cost_complexity_pruning_path(Xd_train, yd_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres=[]\n",
    "for a in ccp_alphas:\n",
    "    st_clf = DecisionTreeClassifier(random_state=0, ccp_alpha= a)\n",
    "    cvclf = cross_validate(st_clf, Xd_train, yd_train, cv=5, scoring='accuracy')\n",
    "    cvres.append(cvclf['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "al=ccp_alphas[np.argmax(cvres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_clf = DecisionTreeClassifier(random_state=0, ccp_alpha=al).fit(Xd_train,yd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(our_clf.predict(Xd_test),yd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-point",
   "metadata": {},
   "source": [
    "Bagging improves on a single tree. Boosting and RF both improve on bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-atmosphere",
   "metadata": {},
   "source": [
    "Oh yeah-- maybe we should draw a picture of the decision boundary when there are two features since we've done that before for non-tree based methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "mX,my = datasets.make_moons(n_samples=500)\n",
    "jig=np.random.normal(0,.2,size=[500,2])\n",
    "\n",
    "mdf=pd.DataFrame(mX+jig,columns=['feat1','feat2'])\n",
    "mdf['Class']=my\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_train, Xn_test, yn_train, yn_test = train_test_split(mdf[['feat1','feat2']], mdf['Class'], test_size=0.3, random_state=5)\n",
    "nclf = GradientBoostingClassifier(n_estimators=600, learning_rate=0.01,max_depth=2, random_state=0).fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.linspace(-2, 3, 500), np.linspace(-1.5, 2, 500))\n",
    "X_grid = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "zz_nn = nclf.predict_proba(X_grid)[:,1].reshape(xx.shape)\n",
    "f, ax = plt.subplots(figsize=(10, 6.6))\n",
    "sns.scatterplot(x='feat1',y='feat2',hue='Class',style='Class',data=mdf)\n",
    "plt.contourf(xx, yy, zz_nn > 0.5, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-brush",
   "metadata": {},
   "source": [
    "Of course, there's not really that much room to shine with only two features..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-bunch",
   "metadata": {},
   "source": [
    "Here's another example. We have 10 features which are all independent $N(0,1)$ observations. If the sum of the 10 exceeds 9.34, then class =1, else class = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "Xh, yh = make_hastie_10_2(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "yh[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-spyware",
   "metadata": {},
   "source": [
    "Plotting column 3 versus column 7 colored by class... don't see much there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(Xh[:,3], Xh[:,7], marker=\"+\",linewidths=1,c=yh, cmap=plt.cm.coolwarm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xh_train, Xh_test, yh_train, yh_test = train_test_split(Xh,yh,test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfh_clf = RandomForestClassifier(n_estimators=600,max_depth=2, oob_score=True,max_features='sqrt',random_state=0).fit(Xh_train,yh_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(rfh_clf.predict(Xh_test),yh_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-blink",
   "metadata": {},
   "source": [
    "Since random forest classifier is built on bootstrapoping it can give OOB score also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfh_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_clf = GradientBoostingClassifier(n_estimators=600, learning_rate=0.01,max_depth=2, random_state=0).fit(Xh_train, yh_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(bst_clf.predict(Xh_test),yh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression(random_state=0).fit(Xh_train, yh_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(lm.predict(Xh_test),yh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh=pd.read_csv('BigFish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh=pd.get_dummies(fsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf=fsh.drop('Weight',axis=1)\n",
    "yf=fsh['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(Xf,yf,test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fsh = RandomForestRegressor(n_estimators=200,max_features='sqrt',random_state=0).fit(Xf_train,yf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fsh.score(Xf_test,yf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-attack",
   "metadata": {},
   "source": [
    "(Ridge regression gets r^2=.875 ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat=Xf.shape[1]\n",
    "plt.barh(np.arange(nfeat),rf_fsh.feature_importances_,align='center')\n",
    "plt.yticks(np.arange(nfeat),list(Xf.columns))\n",
    "plt.ylim(-1,nfeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-albert",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-prize",
   "metadata": {},
   "source": [
    "* Breast Cancer data: Try knn and tree-based classifiers\n",
    "* Boston housing: try tree based regressors for MEDV\n",
    "* Carseats define a Class on Sales where CLass = 1 if Sales > 8 and 0 otherwise. Compare tree-based classifiers to knn.\n",
    "* Carseats II: Perform tree-based regression on Sales.\n",
    "* Try tree-based classifiers on the two moons (arcs) dataset and the circular HW dataset\n",
    "* Try predicting Target in the ```classify_me.csv``` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcd,ycd=sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "bcd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbos,ybos=datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-conference",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
