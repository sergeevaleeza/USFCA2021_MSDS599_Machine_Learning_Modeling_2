{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b408846",
   "metadata": {},
   "source": [
    "## Text data, deep learning, word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada221da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832fe15",
   "metadata": {},
   "source": [
    "First, just for fun..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62cea1",
   "metadata": {},
   "source": [
    "```conda install -c conda-forge wordcloud```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e5301",
   "metadata": {},
   "source": [
    "For later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d12b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): / "
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87187d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ea7cad3705d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c44b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigabe=[\"Four score and seven years ago our fathers brought forth upon this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.But, in a larger sense, we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation, under God, shall have a new birth of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87672a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigabe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bigabe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigabe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a08fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0177d28",
   "metadata": {},
   "source": [
    "Grab that big long string -- get rid of punctuation, and split into separate words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"Working with text can be fun, but can be frustrating too.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f70cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"!Punctuation!can.be.pretty,;: superfluous.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c127ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"[^\\w]\", \" \",  s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf57bd2",
   "metadata": {},
   "source": [
    "The \"\\w\" means \"any word character\" -- alphanumeric (letters, numbers, regardless of case) or an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e277ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"[^\\w]\", \" \",  s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = re.sub(\"[^\\w]\", \" \",  bigabe[0]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa66c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(bigabe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c44287",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c2b2a",
   "metadata": {},
   "source": [
    "Or..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e98815",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='grey').generate(bigabe[0])\n",
    "plt.figure( figsize=(15,10) )\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c0545",
   "metadata": {},
   "source": [
    "Another example -- let's go get some text from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32452612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://serc.carleton.edu/download/files/193011/plain_text_version_declaration_inde.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41290125",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def832a",
   "metadata": {},
   "source": [
    "We need to convert the ```bytes``` object to a string, but actually wordcloud will handle the regular expression processing (recognizing we don't want punctuation or symbols in the word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd39f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(response)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee9f6c",
   "metadata": {},
   "source": [
    "We can do this manually as above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bca3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = re.sub(\"[^\\w]\", \" \", str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96557d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a638d5f7",
   "metadata": {},
   "source": [
    "Or just directly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047934d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white',random_state=0).generate(str(response))\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3764f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(random_state=0).generate(str(response))\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4007e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd917b",
   "metadata": {},
   "source": [
    "Can use shapes (masks) to generate wordclouds within the particular shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_mask = np.array(Image.open('us_map.png'))\n",
    "trooper=np.array(Image.open('troop.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b769a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white',mask=map_mask,random_state=0).generate(str(response))\n",
    "plt.figure( figsize=(18,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white',mask=trooper,contour_width=2,contour_color='black',random_state=0).generate(str(response))\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a68a52",
   "metadata": {},
   "source": [
    "More involved... Sometimes can we actually use text as features in a model. A natural application of this is ***sentiment analysis***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9e7a4",
   "metadata": {},
   "source": [
    "Can we predict whether a movie review is positive or negative? \n",
    "\n",
    "This would be relatively easy (if time consuming) for a human. Seems pretty hard for a machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86282292",
   "metadata": {},
   "source": [
    "Download and unzip: [IMDB movie reviews](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da286804",
   "metadata": {},
   "source": [
    "Then, delete the \"unsup\" folder inside train so you only have \"pos\" and \"neg\" folders inside the \"test\" and \"train\" folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39272f",
   "metadata": {},
   "source": [
    "Finally, copy the filepath to the \"train\" folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a827ea",
   "metadata": {},
   "source": [
    "And load the training data. Note: it took a little under a minute to load on my machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "rev_train = load_files(\"/Users/smdevlin/Dropbox/Teaching/CertA/data/aclImdb/train/\")\n",
    "t1=time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d77a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train,y_train = rev_train.data, rev_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffbcd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(text_train),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca94a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4460b48",
   "metadata": {},
   "source": [
    "The prefix 'b' is telling us that this is a ``bytes`` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d97862",
   "metadata": {},
   "source": [
    "Let's remove the HTML code in there..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa89a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\",b\"\") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abf7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7439f25",
   "metadata": {},
   "source": [
    "A lot of other cleaning, stripping, etc. can be done as above. For example, replace non-alphanumeric strings with empty spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ceef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"[^\\w]\", \" \",  str(text_train[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca59c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9987bb",
   "metadata": {},
   "source": [
    "So, ```y_train``` is telling us if the review is positive (1) or negative (0). Clearly, ```y_train[3]=0```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train[9],\":\",y_train[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49723e6",
   "metadata": {},
   "source": [
    "The data also contains a test set. Read in using ```load_files``` and point to the test folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_test=load_files(\"/Users/smdevlin/Dropbox/Teaching/CertA/data/aclImdb/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test,y_test = rev_test.data, rev_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50245ea9",
   "metadata": {},
   "source": [
    "Get rid of html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e437f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test=[doc.replace(b\"br />\",b\"\") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e49222",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1516a55",
   "metadata": {},
   "source": [
    "Now, the plan is to generate features from the text that we can use to predict whether a review is positive or negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a69f3",
   "metadata": {},
   "source": [
    "First here's a small example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "abe=[\"Four score and seven years ago, our fathers brought forth apon this continent a new nation, conceived in liberty, and dedicated to the proposition that all men are created equal.\",\n",
    "     \"Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafed1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9981c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "abe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "abe[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7897f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer()\n",
    "vect.fit(abe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221584ba",
   "metadata": {},
   "source": [
    "CountVectorizer creates a vocabulary-- all lower case, no punctuation, elimanates some words like 'a'. (Note: the numbers here are locations when the words are organized alphabetically: 'four' is in position 18.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "abe_vect=vect.transform(abe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541d26e",
   "metadata": {},
   "source": [
    "The words become features (columns), and each 'sentence' (could be a sentence or a whole movie review) is a vector (row) whose entries tell us how many times that feature appears in that row.\n",
    "\n",
    "This is stored in a matrix with rows = number of sentences and cols = number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c95657",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr(abe_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ef14a",
   "metadata": {},
   "source": [
    "There were two sentences and 42 words so this is a 2 by 42 matrix. Sparse means there are a LOT of 0s. The computer doesn't store all the zeros -- too wasteful. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d61ed1",
   "metadata": {},
   "source": [
    "For a small example like ours we can look at the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abe_vect.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ee048",
   "metadata": {},
   "source": [
    "The words are in alphabetical order (ago, all, and...); and \"*and*\" appears twice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b876616",
   "metadata": {},
   "source": [
    "Note, this simply looks at which words appear in which reviews (or sentences). No context or relationships between them, etc. Not like real langauge: This is called a \"*bag of words*\" approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d3029",
   "metadata": {},
   "source": [
    "OK -- back to movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer().fit(text_train)\n",
    "X_train=vect.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a867176",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4569ca7",
   "metadata": {},
   "source": [
    "25000 reviews (rows), 75,911 features = words (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847d9aa",
   "metadata": {},
   "source": [
    "We can access the features to explore them a little..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feats[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc2879",
   "metadata": {},
   "source": [
    "Hmmm -- maybe not all the features are particularly useful. We could (should) do some cleaning. We'll do some a bit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feats[19010:19040])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b91a9",
   "metadata": {},
   "source": [
    "We also get lots of variants on a single word which we may or may not want to keep.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d95ff",
   "metadata": {},
   "source": [
    "Also, we may not want to just throw away all numeric features. Maybe 007 comes from James Bond movies? Let's check... pull out some reviews containing \"007\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95465e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep=[]\n",
    "for i in range(len(text_train)):\n",
    "    if \"007\" in str(text_train[i]):\n",
    "        keep.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keep[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815a46f",
   "metadata": {},
   "source": [
    "Sometimes yes (note also this seems to be a video game review):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24300f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train[3082]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657235a6",
   "metadata": {},
   "source": [
    "Sometimes no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train[131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d990730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead24bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaea2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3fe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54f563",
   "metadata": {},
   "source": [
    "Let's see what we get by training a Logistic Regression model on the training data. There are a LOT of features, clearly... almost 76k. More features than observations in fact!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355b248",
   "metadata": {},
   "source": [
    "We will just run 5 fold cross validation and keep track of the scores to see how the accuracy looks on the hold-out fold (not tuning any parameters here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842b2c3",
   "metadata": {},
   "source": [
    "We get some convergence warnings -- typically we dealt with this by scaling the data but it may not be a good idea to do so here. \n",
    " * given the number of features and observations it's not terribly surprising.\n",
    " * our data is sparse and destroying that sparsity (which scaling will do) might not be a great idea.\n",
    " * turns out it's not a big problem here. (Features are not on different scales.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ff295",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe84ad",
   "metadata": {},
   "source": [
    "That's not too bad!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.mean(scores),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa003d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bc91c",
   "metadata": {},
   "source": [
    "Re-train on the full training set (we're going to get a convergence error again)... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af83f8b",
   "metadata": {},
   "source": [
    "``sklearn`` works nicely with the sparse matrix data structure (X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1465908",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,lrm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test,lrm.predict(X_test),colnames=['Prediction'],rownames=['Actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5af4f8",
   "metadata": {},
   "source": [
    "Let's peek at a review where we missed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((lrm.predict(X_test)==1)&(y_test==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6cd9a6",
   "metadata": {},
   "source": [
    "So we predicted positive and they were negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79155e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913c2dc",
   "metadata": {},
   "source": [
    "Understandable? A negative review of one epsiode of the Twilight Zone with positive embedded comments about the series. Context might help-- words that appear near one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1089dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da294ad6",
   "metadata": {},
   "source": [
    "That one is a less excusable mistake, but does positive comments in it: \"acting was as good as it gets...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4beb5f",
   "metadata": {},
   "source": [
    "Note: Different from statsmodels, sklearn's logistic regression automatically uses an L-2 penalty, but it's flipped -- larger C means smaller penalty. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dcb91e",
   "metadata": {},
   "source": [
    "Tuning it might be able to help a little..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3108b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'C':[0.001,0.01,0.10,1,10]}\n",
    "grid = GridSearchCV(LogisticRegression(),param_grid,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f3490",
   "metadata": {},
   "source": [
    "Lot's of errors will get thrown here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45320822",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed4e54",
   "metadata": {},
   "source": [
    "Note: A nice feature of GridSearchCV (that we haven't used in the past) is that it automatically refits the model with optimal parameters on the full training set. We can access the score on the test set as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(grid.score(X_test,y_test),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6d4c5",
   "metadata": {},
   "source": [
    "rounds to 0.88 so slight improvement! (previously 0.8668)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3b73e6",
   "metadata": {},
   "source": [
    "Not bad at all. We can refine (or at least clean up) the model by only using features that apper in at least $n$ training documents ($n>1$) -- since it seems unlikely that a word in only 1 doc will show up in the test set too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49458697",
   "metadata": {},
   "source": [
    "Easy: just use the min_df (df=document frequency) setting in CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0461f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=10).fit(text_train)\n",
    "X_train=vect.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98654115",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c83ecf",
   "metadata": {},
   "source": [
    "Now we have 18,515 features instead of 75,911 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=vect.get_feature_names()\n",
    "print(feature_names[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db9ba7",
   "metadata": {},
   "source": [
    "Though looks like we could still clean up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983be1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names[9100:9150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57890a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid,cv=5)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb74cbe",
   "metadata": {},
   "source": [
    "Similar to before but much fewer features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5113b1b",
   "metadata": {},
   "source": [
    "## Rescaling with tf-idf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82acbc23",
   "metadata": {},
   "source": [
    "Rather than simply counting the number of times a word appears in a document, we try to weigh the features so that more important (revealing) features have higher weight. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9062a58",
   "metadata": {},
   "source": [
    "One way to do this is using ***tf-idf*** : term frequency - inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8688ab7",
   "metadata": {},
   "source": [
    "Give more weight to words that appear often in a particular document (review) but infrequently across the whole set of documents. Those words may be particularly revealing as relates to the content of the document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd882aa",
   "metadata": {},
   "source": [
    "$$\n",
    "tfidf(w,d) = tf \\cdot \\log(\\frac{N+1}{N_w+1})+1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46aa204",
   "metadata": {},
   "source": [
    "* $N$ = number of documents.\n",
    "* $N_w$ = number of documents containing word $w$.\n",
    "* $tf$ = number of times $w$ appears in document $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c258f85",
   "metadata": {},
   "source": [
    "Let's say we want to perform tfidf scaling and cross validation (on the logistic regression parameter C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29605f1",
   "metadata": {},
   "source": [
    "We run into a subtle issue worth pointing out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f4eae",
   "metadata": {},
   "source": [
    "<img src=\"Leakage.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf9023",
   "metadata": {},
   "source": [
    "How to fix? Re-scale the data for each re-training on the training folds, test on the *separately* re-scaled test fold. (Simulate what new data will look like to the model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228f658",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a608e5b5",
   "metadata": {},
   "source": [
    "```sklearn``` provides a method for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748280c7",
   "metadata": {},
   "source": [
    "Tell sklearn what we want to do to our data and in what order: for us, first scale, then logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa06ee2",
   "metadata": {},
   "source": [
    "We want tfidf then LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb117bf2",
   "metadata": {},
   "source": [
    "We have to name each operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\",TfidfVectorizer(min_df=5)),(\"logisticregression\",LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5f40c",
   "metadata": {},
   "source": [
    "Now we tell sklearn which parameters to search over, and which part of the pipeline they belong to-- using our names above and double underscore: __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c251ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_param_grid={'logisticregression__C':[0.001,0.01,0.10,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grid=GridSearchCV(pipe, param_grid=new_param_grid,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grid.fit(text_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdf603",
   "metadata": {},
   "source": [
    "Looks OK  -- just the usual LR convergence warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a1f11d",
   "metadata": {},
   "source": [
    "Barely detectable difference: before we had 0.88832"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b9048",
   "metadata": {},
   "source": [
    "Let's look at which features tf-idf thought were important:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faba141",
   "metadata": {},
   "source": [
    "Thhe pipeline syntax makes it a bit of a hassle to get at the various functions we've used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954737b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=new_grid.best_estimator_.named_steps['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca0a57",
   "metadata": {},
   "source": [
    "Apply to the text_train data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776afee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = vectorizer.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = X_train_tf.max(axis=0).toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba079b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_tfidf = max_val.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01c633",
   "metadata": {},
   "source": [
    "Highest tfidf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names[sorted_by_tfidf[-30:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f901df",
   "metadata": {},
   "source": [
    "Kinda sorta makes sense --  but it's not really helping us zoom in on pos vs. neg reviews. It's more picking out specific movies or shows. Maybe that's why it didn't really help much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e13aef",
   "metadata": {},
   "source": [
    "Let's pull out the coeficients of the features in the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c433201",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = new_grid.best_estimator_.named_steps['logisticregression'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4259fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d2026",
   "metadata": {},
   "source": [
    "And see which one's were most important: both + and -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd2d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pos=np.argsort(coefs)[-10:]\n",
    "top_neg=np.argsort(coefs)[:10]\n",
    "most_infl=np.hstack([top_neg,top_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e52216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(np.arange(20), coefs[most_infl])\n",
    "feature_names = np.array(feature_names)\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "plt.xticks(np.arange(0,20),feature_names[most_infl], rotation=60,ha=\"right\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89818271",
   "metadata": {},
   "source": [
    "## n-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabda644",
   "metadata": {},
   "source": [
    "The bag of words model discards word order and association, both of which are certainly relevant!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73459b",
   "metadata": {},
   "source": [
    "Phrases like \"not too bad!\" and \"just too bad!\" are very similar without the context given by the immediate neighbors of \"bad\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea660d2",
   "metadata": {},
   "source": [
    "One approach is to include n-grams : groups of $n$ words that come togther."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2)).fit(abe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeda86f",
   "metadata": {},
   "source": [
    "```ngram_range=(1,2)``` uses words and pairs of words. That can help but will also blow up the number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d298b",
   "metadata": {},
   "source": [
    "Let's take a swing at movie review using trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"scaler\",TfidfVectorizer(min_df=5)),(\"logisticregression\",LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3290b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_param_grid={'logisticregression__C':[0.001,0.01,0.10,1,10],\"scaler__ngram_range\":[(1,3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggrid=GridSearchCV(pipe, param_grid=tri_param_grid,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073aa5ed",
   "metadata": {},
   "source": [
    "### WARNING: Slow! Takes almost 10 minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t0=time.time()\n",
    "#ggrid.fit(text_train,y_train)\n",
    "#t1=time.time()\n",
    "#print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9713e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggrid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f520d",
   "metadata": {},
   "source": [
    "Helped a little!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f378550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggrid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a9fbc",
   "metadata": {},
   "source": [
    "Now, re-scale test data using Tfidfvectorizer with min_df=5 and ngram_range=(1,3) and apply model to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea926b",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84927c5",
   "metadata": {},
   "source": [
    "One of the most important advances in ML in the last decade. BUT... it has limitations and difficulties that make all the other techniques we've studied important and (still) relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19a37e",
   "metadata": {},
   "source": [
    "In particular, Deep Learning models have many parameters that need to be tuned carefully. It can be difficult, time consuming, and computationally expensive to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ebf45",
   "metadata": {},
   "source": [
    "Natural applications often involve very large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a50d31",
   "metadata": {},
   "source": [
    "We'll consider a simple example of a feed-forward Neural Network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878dbdc",
   "metadata": {},
   "source": [
    "*Image from ISL: James, Witten, Hastie, Tibshirani.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f2ce0",
   "metadata": {},
   "source": [
    "<img src=\"SingleLayerNNpic.png\" width=600, height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685d4a8",
   "metadata": {},
   "source": [
    "Basic idea: \n",
    "\n",
    " * Model takes inputs $X_1,X_2,\\ldots X_p$ (Input Layer).\n",
    " * Each input node feeds into the ***hidden layer units***. The hidden layer consist of $K$ ***activations***:$A_1,\\ldots A_K$.\n",
    " * The $K$ activations feed into the ***output*** layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecb08e",
   "metadata": {},
   "source": [
    "Mathematically, the output layer is a linear regression model in the activations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3157ca",
   "metadata": {},
   "source": [
    "$$\n",
    "f(X)= \\beta_0 + \\sum_{k=1}^K\\beta_kA_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87288853",
   "metadata": {},
   "source": [
    "And where the activations are ***nonlinear*** functions of the inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38537d3",
   "metadata": {},
   "source": [
    "For $k=1,2,\\ldots K$,\n",
    "$$\n",
    "A_k = h_k(X)= g(w_{k0}+\\sum_{j=1}^pw_{kj}X_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9cf2d0",
   "metadata": {},
   "source": [
    "and where $g$ is a nonlinear activation function: usually a *rectified linear unit* or ReLU, which is zero below a threshold and linear above it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27021672",
   "metadata": {},
   "source": [
    "<img src=\"relu_pic.png\" width=300, height=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8b46e",
   "metadata": {},
   "source": [
    "All together:\n",
    "$$\n",
    "f(X) = \\beta_0 + \\sum_{k=1}^K\\beta_k\\cdot g(w_{k0}+\\sum_{j=1}^pw_{kj}X_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c2972",
   "metadata": {},
   "source": [
    "Even the simple picture above has 25 parameters that need to be fit. Compare to RF or boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa73408",
   "metadata": {},
   "source": [
    "The nonlinearity is essential -- without it the DL model is just a big linear model. It also allows for extremely complex nonlinear functions of the features to enter the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e24310",
   "metadata": {},
   "source": [
    "DL is supervised! \n",
    "\n",
    "in a regression model we fit parameters to minimize SSE:\n",
    "$$\n",
    "\\sum (y_i - f(X_i))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93ba6e",
   "metadata": {},
   "source": [
    "For classification we use a different loss function (cross entropy) involving the probability of observations being in class $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e74937",
   "metadata": {},
   "source": [
    "We can use:\n",
    "\n",
    "   * many hidden layers (many more parameters)\n",
    "   * many different task appropriate architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0c447",
   "metadata": {},
   "source": [
    "<img src=\"multi_layer_NN_pic.png\" width=600, height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b27506",
   "metadata": {},
   "source": [
    "Examples of different architectures:\n",
    "\n",
    "   * Convolutional Neural Networks : Image classification\n",
    "   * Recurrant Neural Networks : Text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fecb4",
   "metadata": {},
   "source": [
    "We'll consider a few examples... first, a pretrained CNN for image classification: ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d5991",
   "metadata": {},
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bd942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import image\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "img = image.load_img(\"hawk.jpg\", target_size = (224, 224))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5323e",
   "metadata": {},
   "source": [
    "Preprocessing for ResNet: 50 layers pretrained on over 1 million images from the ImageNet database. There are more than 1000 categories (classes).  \n",
    "\n",
    "ResNet50 has over ***23 MILLION*** parameters to train!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de67456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28286cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img)\n",
    "print(\"Predicted:\", decode_predictions(preds, top=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda0513",
   "metadata": {},
   "source": [
    "Wrong already! Or is it? (At least it was not confident...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "img_cr = image.load_img(\"hawk_cropped.jpg\", target_size = (224, 224))\n",
    "plt.imshow(img_cr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cr = image.img_to_array(img_cr)\n",
    "img_cr = np.expand_dims(img_cr, axis=0)\n",
    "img_cr = preprocess_input(img_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0183ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img_cr)\n",
    "print(\"Predicted:\", decode_predictions(preds, top=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a4c51",
   "metadata": {},
   "source": [
    "That's not bad: a kite is a bird of prey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585fd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "img_f = image.load_img(\"flamingo.jpg\", target_size = (224, 224))\n",
    "plt.imshow(img_f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = image.img_to_array(img_f)\n",
    "img_f = np.expand_dims(img_f, axis=0)\n",
    "img_f = preprocess_input(img_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img_f)\n",
    "print(\"Predicted:\", decode_predictions(preds, top=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e031f08",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971dd82f",
   "metadata": {},
   "source": [
    "While the tri-grams (and $n$-grams) capture some context above, they don't capture any relationships between words that don't appear near one another. We're unlikely to realize that 'beautiful' and 'pulchritudinous'; or 'hairy' and 'hirsute,' are close relatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0307d63",
   "metadata": {},
   "source": [
    "Word embeddings attempt to capture this by embedding words in Euclidean space in such a way that the geometry reflects the semantic meanings of the words: similar words are nearby in space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60132fad",
   "metadata": {},
   "source": [
    "Train a NN to predict the next word in a sentence... only throw away the prediction and use the learned weights to represent words in a vector space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b52048",
   "metadata": {},
   "source": [
    "These are usually high-dimensional embeddings (100 dim or more) and are \"learned\" by training a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcae976",
   "metadata": {},
   "source": [
    "Use our IMDB reviews as a corpus... there are pretrained models available (trained on Twitter, Wikipedia, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a448e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[ re.sub(\"[^\\w]\", \" \", str(review)).lower().split() for review in text_train] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ae346",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36d3f5",
   "metadata": {},
   "source": [
    "Let's create a 50 dim embedding. (Note: This should be interesting/fun but isn't big enough and doesn't have enough training data to be truly impressive.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82893c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "model = Word2Vec(texts, vector_size=50, window=10, min_count=5,sample=1e-3, workers=2)\n",
    "t1=time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a04bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='horror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea19e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='fun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(negative='fun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='kids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84481043",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = model.wv['scary'].reshape((1, 50)) + model.wv['blood'].reshape((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3291f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e23e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwvec = model.wv['oscar'].reshape((1, 50)) + model.wv['loser'].reshape((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e731fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=mwvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='vader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251133b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='jabba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='superman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='scorsese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='godfather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff= model.wv['funny'].reshape((1, 50)) - model.wv['important'].reshape((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='hamlet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='cry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='oscar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('darth', 'vader')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
